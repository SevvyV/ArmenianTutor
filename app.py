import streamlit as st
from google import genai
from google.genai import types
import wave
import io

# 1. Page Configuration
st.set_page_config(page_title="HyeTutor2.0beta", page_icon="üá¶üá≤", layout="wide")

st.title("üá¶üá≤ HyeTutor2.0beta")
st.caption("Version 3.4 ‚Ä¢ Cleaned Navigation Logic")

# --- FOUNDATIONS DATA ---
FOUNDATIONS = {
    "üìÖ Days of the Week": "‘µ÷Ä’Ø’∏÷Ç’∑’°’¢’©’´ (Yerkushapti), ‘µ÷Ä’•÷Ñ’∑’°’¢’©’´ (Yerekshapti), ’â’∏÷Ä’•÷Ñ’∑’°’¢’©’´ (Chorekshapti), ’Ä’´’∂’£’∑’°’¢’©’´ (Hingshapti), ’à÷Ç÷Ä’¢’°’© (Urpatt), ’á’°’¢’°’© (Shapat), ‘ø’´÷Ä’°’Ø’´ (Giragi)",
    "üî¢ Numbers (1-10)": "’Ñ’ß’Ø (Meg), ‘µ÷Ä’Ø’∏÷Ç (Yergu), ‘µ÷Ä’•÷Ñ (Yerek), ’â’∏÷Ä’Ω (Chors), ’Ä’´’∂’£ (Hink), ’é’•÷Å (Vets), ‘µ÷Ö’©’® (Yote), ’à÷Ç’©’® (Oote), ‘ª’∂’® (Ine), ’è’°’Ω’® (Dase)",
    "üóìÔ∏è Months of the Year": "’Ö’∏÷Ç’∂’∏÷Ç’°÷Ä (Hoonvar), ’ì’•’ø÷Ä’∏÷Ç’°÷Ä (Pedervar), ’Ñ’°÷Ä’ø (Mard), ‘±’∫÷Ä’´’¨ (Abreel), ’Ñ’°’µ’´’Ω (Mayis), ’Ö’∏÷Ç’∂’´’Ω (Hooneess), ’Ö’∏÷Ç’¨’´’Ω (Hooleess), ’ï’£’∏’Ω’ø’∏’Ω (Okosdos), ’ç’•’∫’ø’•’¥’¢’•÷Ä (Sebdemper), ’Ä’∏’Ø’ø’•’¥’¢’•÷Ä (Hogdemper), ’Ü’∏’µ’•’¥’¢’•÷Ä (Noyemper), ‘¥’•’Ø’ø’•’¥’¢’•÷Ä (Tegdemper)"
}

# --- TOP 50 VERB LIST ---
TOP_50_VERBS = [
    "be", "have", "do", "say", "go", "can", "get", "would", "make", "know",
    "will", "think", "take", "see", "come", "could", "want", "look", "use",
    "find", "give", "tell", "work", "may", "should", "call", "try", "ask",
    "need", "feel", "become", "leave", "put", "mean", "keep", "let", "begin",
    "seem", "help", "talk", "turn", "start", "might", "show", "hear", "play",
    "run", "move", "like", "live"
]

# 2. Key Verification & Audio Utils
api_key = st.secrets["GOOGLE_API_KEY"]
client = genai.Client(api_key=api_key)

def create_wav_file(pcm_data):
    buf = io.BytesIO()
    with wave.open(buf, 'wb') as wf:
        wf.setnchannels(1)
        wf.setsampwidth(2) 
        wf.setframerate(24000)
        wf.writeframes(pcm_data)
    return buf.getvalue()

def speak_text(text_to_speak):
    try:
        tts_response = client.models.generate_content(
            model="gemini-2.5-flash-preview-tts",
            contents=f"Read this clearly in Western Armenian: {text_to_speak}",
            config=types.GenerateContentConfig(response_modalities=["AUDIO"])
        )
        for part in tts_response.candidates[0].content.parts:
            if part.inline_data:
                st.audio(create_wav_file(part.inline_data.data), format="audio/wav")
    except:
        st.warning("Tutor voice engine loading...")

# 3. Dynamic Conjugator Logic
@st.cache_data
def get_conjugation(verb_name, tense_name):
    prompt = f"Conjugate the Western Armenian verb for '{verb_name}' in {tense_name} tense with all 6 pronouns (‘µ’Ω, ‘¥’∏÷Ç’∂, ‘±’∂, ’Ñ’•’∂÷Ñ, ‘¥’∏÷Ç÷Ñ, ‘±’∂’∏’∂÷Ñ). Return as a comma-separated list."
    response = client.models.generate_content(model="gemini-3-flash-preview", contents=prompt)
    return response.text.strip().split(",")

# 4. Sidebar: Master Navigation with Improved Logic
with st.sidebar:
    st.header("üéì Learning Plan")
    main_mode = st.selectbox("Select Learning Category:", ["Foundations", "Top 50 Verbs", "Custom Search"])
    
    st.divider()
    
    # Logic: Only show secondary options relevant to the current mode
    if main_mode == "Foundations":
        sub_selection = st.selectbox("Choose Foundation:", list(FOUNDATIONS.keys()))
        selected_content = FOUNDATIONS[sub_selection]
        mode_label = sub_selection
        tense = None # Not used in foundations
        
    elif main_mode == "Top 50 Verbs":
        sub_selection = st.selectbox("Select Verb:", TOP_50_VERBS)
        tense = st.selectbox("Tense:", ["Past", "Present", "Future"])
        mode_label = f"{sub_selection} ({tense})"
        
    elif main_mode == "Custom Search":
        sub_selection = st.text_input("Type any English verb:", "to sing")
        tense = st.selectbox("Tense:", ["Past", "Present", "Future"])
        mode_label = f"{sub_selection} ({tense})"

# 5. Main Content Logic
if main_mode == "Foundations":
    st.header(mode_label)
    # Highlight the Western Armenian script
    st.info("Listen and repeat the full sequence.")
    st.write(f"### {selected_content}")
    
    if st.button(f"üîä Listen to Native Pronunciation"):
        # We strip the English phonetics (in brackets) for the voice engine
        armenian_only = selected_content.split("(")[0].strip() if "(" in selected_content else selected_content
        speak_text(selected_content)

else:
    # Verb Modes
    if sub_selection:
        with st.spinner(f"Generating lesson for {sub_selection}..."):
            conjugation_list = get_conjugation(sub_selection, tense)
        st.header(f"Verb Practice: {sub_selection}")
        st.subheader(f"Focus: {tense} Tense with Pronouns")
        
        # Display verbs in a clean grid
        cols = st.columns(3)
        for i, item in enumerate(conjugation_list):
            cols[i % 3].write(f"üîπ **{item.strip()}**")
            
        if st.button("üîä Listen and Model"):
            speak_text(", ".join(conjugation_list))

st.divider()

# 6. Global Practice Interaction
audio_data = st.audio_input("Practice your pronunciation")

if audio_data:
    instruct = f"IDENTITY: Elite Western Armenian Tutor. Task: Analyze the user's pronunciation of {mode_label}."
    with st.status("Analyzing..."):
        try:
            audio_part = types.Part.from_bytes(data=audio_data.read(), mime_type="audio/wav")
            analysis = client.models.generate_content(
                model="gemini-3-flash-preview", 
                config={'system_instruction': instruct},
                contents=[audio_part]
            )
            st.success("Tutor's Evaluation:")
            st.markdown(analysis.text)
            # Auto-speak the first line of feedback
            speak_text(analysis.text.split("\n")[0])
        except Exception as e:
            st.error(f"Recording Error: {e}")
