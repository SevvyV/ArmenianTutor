"""
Azure TTS Dual-Voice Audio Generation Script - Complete Rebuild

Generates ALL audio files for Armenian Tutor app with:
- Male voice (Hayk) AND Female voice (Anahit)
- Western Armenian pronunciation hacks for Eastern TTS
- Organized folder structure

Total: ~590 MP3 files (295 per voice)

Usage:
    python generate_audio_dual.py --voice both
    python generate_audio_dual.py --voice male
    python generate_audio_dual.py --lesson greetings_01
"""

import os
import sys
import time
import argparse
import azure.cognitiveservices.speech as speechsdk
from azure.identity import DefaultAzureCredential
from azure.keyvault.secrets import SecretClient
from pathlib import Path
from lessons import LESSONS
from verb_conjugation import VERBS


# ============================================================================
# AZURE KEY VAULT CONFIGURATION
# ============================================================================

KEY_VAULT_URL = "https://kv-vartanian-prod.vault.azure.net/"
SPEECH_KEY_SECRET_NAME = "AzureKey1"


def get_speech_key_from_vault() -> str:
    """Retrieve Azure Speech API key from Key Vault using Azure CLI credentials."""
    try:
        credential = DefaultAzureCredential()
        client = SecretClient(vault_url=KEY_VAULT_URL, credential=credential)
        secret = client.get_secret(SPEECH_KEY_SECRET_NAME)
        print("Retrieved speech key from Key Vault")
        return secret.value
    except Exception as e:
        print(f"Failed to retrieve key from Key Vault: {e}")
        print("   Make sure you have run 'az login' and have access to the vault.")
        sys.exit(1)


# ============================================================================
# WESTERN ARMENIAN PRONUNCIATION HACKS
# ============================================================================
# GUIDE FOR IDENTIFYING WORDS THAT NEED HACKS:
# Azure TTS uses Eastern Armenian pronunciation. Western Armenian spelling
# patterns get mispronounced. Scan new lessons against these patterns.
#
# PATTERN A: Word-final ’°’µ sounds "ay" but should be "ah"
#   Fix: drop the final ’µ so Azure says "ah" not "ay"
#   Examples: ’é÷Ä’°’µ->"’é÷Ä’°" (Vra), ‘±’Ø’º’°’µ->‘±’Ø’º’° (Agra)
#   EXCEPTIONS: ’Ä’°’µ (Hay=Armenian) - "ay" IS correct, do NOT fix.
#   Also don't fix ’°’µ’´ endings (the ’µ is pronounced before ’´).
#   HOW TO SPOT: phonetic ends in "a" but Armenian text ends in ’°’µ
#
# PATTERN B: ’°÷Ç sounds "aw" but should be "av"
#   Fix: replace ’°÷Ç with ’°’æ so Azure says "av"
#   Examples: ’Ä’°÷Ç (Hav), ‘º’°÷Ç (Lav), ‘±’º’°÷Ç÷Ö’ø (Aravod)
#   HOW TO SPOT: phonetic shows "av" but Azure says "aw"
#
# PATTERN C: Word-final ’ß in verb conjugations
#   Fix: replace ’ß with ’• for better pronunciation
#
# PATTERN D: Past tense ’°÷Ç endings (same as B in verb context)
#
# WHEN ADDING NEW LESSONS:
#   1. Scan for words ending in ’°’µ (Pattern A)
#   2. Scan for words containing ’°÷Ç (Pattern B)
#   3. Test-generate 2-3 flagged words and listen before bulk run
#   4. Add new problem words to WESTERN_TO_EASTERN_FIXES below
# ============================================================================

WESTERN_TO_EASTERN_FIXES = {
    # ========================================================================
    # PATTERN A FIXES: Word-final ’°’µ -> ’° (sounds "ah" not "ay")
    # Exception: ’Ä’°’µ (Hay=Armenian) is correct as-is
    # ========================================================================
    "’é÷Ä’°’µ": "’é’º’°",              # on/on top of (Vra, not Vray)
    "’æ÷Ä’°’µ": "’æ’º’°",              # on/on top of (lowercase)
    "‘±’Ø’º’°’µ": "‘±’Ø’º’°",          # tooth (Agra, not Agray)
    "’π’Ø’°’µ": "’π’Ø’°",              # doesn't exist (chga)
    "’è’≤’°’µ": "’è’≤’°",              # boy/son (Degha, not Deghay)

    # ========================================================================
    # PATTERN B FIXES: ’°÷Ç -> ’°’æ (sounds "av" not "aw") in vocabulary
    # ========================================================================
    "’Ä’°÷Ç": "’Ä’°’æ",                    # chicken (Hav)
    "’Ä’°÷Ç’Ø’´’©": "’Ä’°’æ’Ø’´’©",          # egg (Havgit)
    "‘±’º’°÷Ç÷Ö’ø": "‘±’º’°’æ÷Ö’ø",          # morning (Aravod)
    "’°’º’°÷Ç÷Ö’ø": "’°’º’°’æ÷Ö’ø",          # morning (lowercase)
    "‘≥’°÷Ç’°’©": "‘≥’°’æ’°’©",          # cup (Kavat)
    "’è’°’Ø’°÷Ç’´’∂": "’è’°’Ø’°’æ’´’∂",      # still/yet (Dagavin)
    "’∑’°’¢’°’©’°÷Ç’•÷Ä’ª": "’∑’°’¢’°’©’°’æ’•÷Ä’ª",  # weekend
    "’∞÷Ä’°÷Ç’´÷Ä’•’¥": "’∞÷Ä’°’æ’´÷Ä’•’¥",      # I invite
    "’á’∂’∏÷Ä’∞’°÷Ç’∏÷Ä": "’á’∂’∏÷Ä’∞’°’æ’∏÷Ä",  # congratulations
    "’Å’°÷Ç": "’Å’°’æ",                    # pain (Tsav)
    "‘≥’¨’≠’°÷Å’°÷Ç": "‘≥’¨’≠’°÷Å’°’æ",      # headache
    "‘º’°÷Ç’°’∑": "‘º’°’æ’°’∑",          # lavash
    "‘º’°÷Ç": "‘º’°’æ",                    # good (Lav)
    "’¶’°÷Ç’°’Ø": "’¶’°’æ’°’Ø",          # child (zavag)
    "’¥’°÷Ä’•÷Å’°÷Ç": "’¥’°÷Ä’•÷Å’°’æ",      # died/went out (phone dead)
    "’π’•’Ø’°÷Ç": "’π’•’Ø’°’æ",          # didn't come
    "’π’•’≤’°÷Ç": "’π’•’≤’°’æ",          # didn't happen
    # ========================================================================
    # PATTERN 1: "’°÷Ç" ‚Üí "’°’æ" in past tense verbs (very common!)
    # ========================================================================
    "’®÷Ä’°÷Ç": "’®÷Ä’°’æ",          # did
    "’•’Ø’°÷Ç": "’•’Ø’°’æ",          # came
    "’¢’•÷Ä’°÷Ç": "’¢’•÷Ä’°’æ",        # brought
    "’Ø’•÷Ä’°÷Ç": "’Ø’•÷Ä’°’æ",        # ate
    "’ø’•’Ω’°÷Ç": "’ø’•’Ω’°’æ",        # saw
    "’ø’∏÷Ç’°÷Ç": "’ø’∏÷Ç’°’æ",        # gave
    "’°’º’°÷Ç": "’°’º’°’æ",          # took
    "’£’°÷Å’°÷Ç": "’£’°÷Å’°’æ",        # went (but actual is ’£’°÷Å, not ’£’°÷Å’°÷Ç)
    "’§÷Ä’°÷Ç": "’§÷Ä’°’æ",          # put
    "’¢’°÷Å’°÷Ç": "’¢’°÷Å’°’æ",        # opened
    "’£’∏÷Å’°÷Ç": "’£’∏÷Å’°’æ",        # closed (but actual is ’£’∏÷Å’•÷Å)
    "’∂’Ω’ø’°÷Ç": "’∂’Ω’ø’°’æ",        # sat
    "÷Ñ’∂’°÷Å’°÷Ç": "÷Ñ’∂’°÷Å’°’æ",      # slept
    "’≠÷Ö’Ω’•÷Å’°÷Ç": "’≠÷Ö’Ω’•÷Å’°’æ",    # spoke
    "’Ø’°’µ’∂’•÷Å’°÷Ç": "’Ø’°’µ’∂’•÷Å’°’æ",  # stood
    "’Ω’Ø’Ω’°÷Ç": "’Ω’Ø’Ω’°’æ",        # started
    "’°’∫÷Ä’•÷Å’°÷Ç": "’°’∫÷Ä’•÷Å’°’æ",    # lived
    "’∂’°’µ’•÷Å’°÷Ç": "’∂’°’µ’•÷Å’°’æ",    # looked
    "’Ω’∏÷Ä’æ’•÷Å’°÷Ç": "’Ω’∏÷Ä’æ’•÷Å’°’æ",  # learned
    "’¥’∏’º÷Å’°÷Ç": "’¥’∏’º÷Å’°’æ",      # forgot
    
    # ========================================================================
    # PATTERN 2: "’∏÷Ç’°" ‚Üí "’æ’°" in wash verb conjugations
    # ========================================================================
    "’Ø’® ’¨’∏÷Ç’°’¥": "’Ø’® ’¨’æ’°’¥",
    "’Ø’® ’¨’∏÷Ç’°’Ω": "’Ø’® ’¨’æ’°’Ω",
    "’Ø’® ’¨’∏÷Ç’°’µ": "’Ø’® ’¨’æ’°",
    "’Ø’® ’¨’∏÷Ç’°’∂÷Ñ": "’Ø’® ’¨’æ’°’∂÷Ñ",
    "’Ø’® ’¨’∏÷Ç’°÷Ñ": "’Ø’® ’¨’æ’°÷Ñ",
    "’Ø’® ’¨’∏÷Ç’°’∂": "’Ø’® ’¨’æ’°’∂",
    "’¨’∏÷Ç’°÷Å’´": "’¨’æ’°÷Å’´",
    "’¨’∏÷Ç’°÷Å’´÷Ä": "’¨’æ’°÷Å’´÷Ä",
    "’¨’∏÷Ç’°÷Å": "’¨’æ’°÷Å",
    "’¨’∏÷Ç’°÷Å’´’∂÷Ñ": "’¨’æ’°÷Å’´’∂÷Ñ",
    "’¨’∏÷Ç’°÷Å’´÷Ñ": "’¨’æ’°÷Å’´÷Ñ",
    "’¨’∏÷Ç’°÷Å’´’∂": "’¨’æ’°÷Å’´’∂",
    "’∫’´’ø’´ ’¨’∏÷Ç’°’¥": "’∫’´’ø’´ ’¨’æ’°’¥",
    "’∫’´’ø’´ ’¨’∏÷Ç’°’Ω": "’∫’´’ø’´ ’¨’æ’°’Ω",
    "’∫’´’ø’´ ’¨’∏÷Ç’°’µ": "’∫’´’ø’´ ’¨’æ’°",
    "’∫’´’ø’´ ’¨’∏÷Ç’°’∂÷Ñ": "’∫’´’ø’´ ’¨’æ’°’∂÷Ñ",
    "’∫’´’ø’´ ’¨’∏÷Ç’°÷Ñ": "’∫’´’ø’´ ’¨’æ’°÷Ñ",
    "’∫’´’ø’´ ’¨’∏÷Ç’°’∂": "’∫’´’ø’´ ’¨’æ’°’∂",
    
    # ========================================================================
    # PATTERN 3: Word-final "’°’µ" ‚Üí "’°" (drop silent ’µ) - KEEP THIS
    # NOTE: "’Ø’® ’∂’°’µ’´" should stay as "’∂’°’µ’´" (pronounced "nayee")
    # Only fix word-final ’°’µ, not ’°’µ’´
    # ========================================================================
    "’Ø'’°÷Ä’©’∂’∂’°’µ": "’Ø'’°÷Ä’©’∂’∂’°",
    "’Ø'’•÷Ä’©’°’µ": "’Ø'’•÷Ä’©’°",
    "’Ø’∏÷Ç ’£’°’µ": "’Ø’∏÷Ç ’£’°",
    "’Ø’® ’ø’°’µ": "’Ø’® ’ø’°",
    "’Ø’® ’Ø’°÷Ä’§’°’µ": "’Ø’® ’Ø’°÷Ä’§’°",
    "’Ø’® ’≠’°’≤’°’µ": "’Ø’® ’≠’°’≤’°",
    "’∫’´’ø’´ ’®’¨’¨’°’µ": "’∫’´’ø’´ ’®’¨’¨’°",
    "’∫’´’ø’´ ’•÷Ä’©’°’µ": "’∫’´’ø’´ ’•÷Ä’©’°",
    "’∫’´’ø’´ ’£’°’µ": "’∫’´’ø’´ ’£’°",
    "’∫’´’ø’´ ’ø’°’µ": "’∫’´’ø’´ ’ø’°",
    "’∫’´’ø’´ ’Ø’°÷Ä’§’°’µ": "’∫’´’ø’´ ’Ø’°÷Ä’§’°",
    "’∫’´’ø’´ ’≠’°’≤’°’µ": "’∫’´’ø’´ ’≠’°’≤’°",
    "’∫’´’ø’´ ’¢’°’∂’°’µ": "’∫’´’ø’´ ’¢’°’∂’°",      # will open
    "’Ø’® ’¢’°’∂’°’µ": "’Ø’® ’¢’°’∂’°",            # opens
    "’∫’´’ø’´ ’°÷Ä’©’∂’∂’°’µ": "’∫’´’ø’´ ’°÷Ä’©’∂’∂’°",  # will wake up
    "’∫’´’ø’´ ÷Ñ’∂’°’∂’°’µ": "’∫’´’ø’´ ÷Ñ’∂’°’∂’°",    # will sleep
    "’Ø’® ÷Ñ’∂’°’∂’°’µ": "’Ø’® ÷Ñ’∂’°’∂’°",          # sleeps
    "’∫’´’ø’´ ’∏÷Ç’∂’•’∂’°’µ": "’∫’´’ø’´ ’∏÷Ç’∂’•’∂’°",  # will have
    "’∫’´’ø’´ ’£’´’ø’∂’°’µ": "’∫’´’ø’´ ’£’´’ø’∂’°",    # will know
    "’∫’´’ø’´ ’¥’∏’º’∂’°’µ": "’∫’´’ø’´ ’¥’∏’º’∂’°",    # will forget
    "’∫’´’ø’´ ’∞’°’Ω’Ø’∂’°’µ": "’∫’´’ø’´ ’∞’°’Ω’Ø’∂’°",  # will understand
    "’Ø’® ’¥’∏’º’∂’°’µ": "’Ø’® ’¥’∏’º’∂’°",          # forgets
    "’Ø’® ’∞’°’Ω’Ø’∂’°’µ": "’Ø’® ’∞’°’Ω’Ø’∂’°",        # understands
    
    # ========================================================================
    # PATTERN 4: "’ß" ‚Üí "’•" for better TTS (word-final ’ß can sound off)
    # ========================================================================
    "’Ø'’∏÷Ç’¶’ß": "’Ø'’∏÷Ç’¶’•",
    "’Ø’® ’Ω’´÷Ä’ß": "’Ø’® ’Ω’´÷Ä’•",
    "’Ø’® ’£÷Ä’ß": "’Ø’® ’£÷Ä’•",
    "’Ø’® ’¢’•÷Ä’ß": "’Ø’® ’¢’•÷Ä’•",
    "’Ø'’®’∂’ß": "’Ø'’®’∂’•",
    "’Ø’® ’ø’•’Ω’∂’ß": "’Ø’® ’ø’•’Ω’∂’•",
    "’Ø’® ’¨’Ω’ß": "’Ø’® ’¨’Ω’•",
    "’Ø’® ’≠’¥’ß": "’Ø’® ’≠’¥’•",
    "’Ø'’∏÷Ç’ø’ß": "’Ø'’∏÷Ç’ø’•",
    "’Ø’® ’§’∂’ß": "’Ø’® ’§’∂’•",
    "’Ø'’°’º’∂’ß": "’Ø'’°’º’∂’•",
    "’Ø'÷Ö’£’∂’ß": "’Ø'÷Ö’£’∂’•",
    "’£’´’ø’ß": "’£’´’ø’•",
    "’∏÷Ç’∂’´": "’∏÷Ç’∂’´",  # This one is already "’´" not "’ß"
}


def apply_western_fixes(armenian_text: str) -> str:
    """
    Apply Western ‚Üí Eastern pronunciation hacks for better TTS.
    
    Args:
        armenian_text: Original Western Armenian text
    
    Returns:
        Modified text optimized for Azure TTS
    """
    text = armenian_text
    
    # Apply known fixes
    for western, eastern in WESTERN_TO_EASTERN_FIXES.items():
        text = text.replace(western, eastern)
    
    return text


# ============================================================================
# DUAL-VOICE TTS ENGINE
# ============================================================================

class DualVoiceTTS:
    """
    Handles text-to-speech for both male and female voices.
    """
    
    VOICES = {
        "male": "hy-AM-HaykNeural",
        "female": "hy-AM-AnahitNeural",
    }
    
    def __init__(self, subscription_key: str, region: str = "eastus"):
        """
        Initialize Azure Speech SDK.
        
        Args:
            subscription_key: Azure Speech API key
            region: Azure region
        """
        self.subscription_key = subscription_key
        self.region = region
    
    def synthesize_to_file_ssml(
        self, 
        ssml_text: str, 
        output_path: str, 
        voice: str = "male",
        delay: float = 1.0
    ) -> bool:
        """
        Generate audio file from SSML (for pauses, emphasis, etc).
        
        Args:
            ssml_text: SSML text with markup (e.g., <speak>text<break time="500ms"/>more</speak>)
            output_path: Full path where MP3 should be saved
            voice: "male" or "female"
            delay: Delay in seconds after each API call
        
        Returns:
            True if successful, False otherwise
        """
        # Convert path to absolute and normalize for Windows
        output_path = os.path.abspath(output_path)
        
        # Create parent directory
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        # Verify directory was created
        if not os.path.exists(os.path.dirname(output_path)):
            print(f"   ‚ùå Failed to create directory: {os.path.dirname(output_path)}")
            return False
        
        # Configure voice
        speech_config = speechsdk.SpeechConfig(
            subscription=self.subscription_key,
            region=self.region
        )
        speech_config.speech_synthesis_voice_name = self.VOICES[voice]
        
        # Configure audio output
        audio_config = speechsdk.audio.AudioOutputConfig(filename=output_path)
        
        # Create synthesizer
        try:
            synthesizer = speechsdk.SpeechSynthesizer(
                speech_config=speech_config,
                audio_config=audio_config
            )
        except Exception as e:
            print(f"   ‚ùå Synthesizer creation failed: {str(e)}")
            return False
        
        # Synthesize using SSML
        result = synthesizer.speak_ssml_async(ssml_text).get()
        
        # Add delay to prevent rate limiting
        time.sleep(delay)
        
        # Check result
        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            return True
        elif result.reason == speechsdk.ResultReason.Canceled:
            cancellation = result.cancellation_details
            print(f"   ‚ùå Failed: {cancellation.reason}")
            if cancellation.error_details:
                print(f"      Error: {cancellation.error_details}")
            return False
        else:
            return False
    
    def synthesize_to_file(
        self, 
        text: str, 
        output_path: str, 
        voice: str = "male",
        apply_fixes: bool = True,
        delay: float = 1.0
    ) -> bool:
        """
        Generate audio file from Armenian text.
        
        Args:
            text: Armenian text (Western spelling)
            output_path: Full path where MP3 should be saved
            voice: "male" or "female"
            apply_fixes: Whether to apply Western‚ÜíEastern pronunciation hacks
            delay: Delay in seconds after each API call (prevents rate limiting)
        
        Returns:
            True if successful, False otherwise
        """
        # Apply pronunciation fixes
        if apply_fixes:
            tts_text = apply_western_fixes(text)
        else:
            tts_text = text
        
        # Convert path to absolute and normalize for Windows
        output_path = os.path.abspath(output_path)
        
        # Create parent directory
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        
        # Verify directory was created
        if not os.path.exists(os.path.dirname(output_path)):
            print(f"   ‚ùå Failed to create directory: {os.path.dirname(output_path)}")
            return False
        
        # Configure voice
        speech_config = speechsdk.SpeechConfig(
            subscription=self.subscription_key,
            region=self.region
        )
        speech_config.speech_synthesis_voice_name = self.VOICES[voice]
        
        # Configure audio output - use absolute path
        audio_config = speechsdk.audio.AudioOutputConfig(filename=output_path)
        
        # Create synthesizer
        try:
            synthesizer = speechsdk.SpeechSynthesizer(
                speech_config=speech_config,
                audio_config=audio_config
            )
        except Exception as e:
            print(f"   ‚ùå Synthesizer creation failed: {str(e)}")
            return False
        
        # Synthesize
        result = synthesizer.speak_text_async(tts_text).get()
        
        # Add delay to prevent rate limiting
        time.sleep(delay)
        
        # Check result
        if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
            return True
        elif result.reason == speechsdk.ResultReason.Canceled:
            cancellation = result.cancellation_details
            print(f"   ‚ùå Failed: {cancellation.reason}")
            if cancellation.error_details:
                print(f"      Error: {cancellation.error_details}")
            return False
        else:
            return False


# ============================================================================
# AUDIO GENERATION FUNCTIONS
# ============================================================================

def generate_vocabulary_audio(tts: DualVoiceTTS, voices: list, output_dir: str = "audio_library"):
    """Generate audio for all vocabulary lessons."""
    
    print("\n" + "="*70)
    print("üìö GENERATING VOCABULARY AUDIO")
    print("="*70)
    
    stats = {"total": 0, "success": 0, "failed": 0, "skipped": 0}
    
    for lesson_id, lesson in LESSONS.items():
        if lesson.lesson_type != "vocabulary":
            continue
        
        print(f"\nüìñ {lesson.title}")
        print(f"   Items: {len(lesson.items)}")
        
        for voice in voices:
            print(f"   Voice: {voice.capitalize()}")
            
            # Build output path: vocabulary/{lesson_id}/{voice}/
            voice_dir = f"{output_dir}/vocabulary/{lesson_id}/{voice}"
            
            for item in lesson.items:
                stats["total"] += 1
                output_path = f"{voice_dir}/{item.audio_key}.mp3"
                
                # Skip if exists
                if os.path.exists(output_path):
                    stats["skipped"] += 1
                    continue
                
                # Get text (use armenian_audio if present, else armenian_display)
                text = (item.armenian_audio if hasattr(item, 'armenian_audio') and item.armenian_audio 
                       else item.armenian_display)
                
                # Generate
                if tts.synthesize_to_file(text, output_path, voice):
                    print(f"      ‚úÖ {item.audio_key}.mp3")
                    stats["success"] += 1
                else:
                    print(f"      ‚ùå {item.audio_key}.mp3 FAILED")
                    stats["failed"] += 1
    
    return stats


def generate_sentence_audio(tts: DualVoiceTTS, voices: list, output_dir: str = "audio_library"):
    """Generate audio for all sentence lessons."""
    
    print("\n" + "="*70)
    print("üí¨ GENERATING SENTENCE AUDIO")
    print("="*70)
    
    stats = {"total": 0, "success": 0, "failed": 0, "skipped": 0}
    
    for lesson_id, lesson in LESSONS.items():
        if lesson.lesson_type != "sentences":
            continue
        
        print(f"\nüìù {lesson.title}")
        print(f"   Items: {len(lesson.items)}")
        
        for voice in voices:
            print(f"   Voice: {voice.capitalize()}")
            
            # Build output path: sentences/{lesson_id}/{voice}/
            voice_dir = f"{output_dir}/sentences/{lesson_id}/{voice}"
            
            for item in lesson.items:
                stats["total"] += 1
                output_path = f"{voice_dir}/{item.audio_key}.mp3"
                
                # Skip if exists
                if os.path.exists(output_path):
                    stats["skipped"] += 1
                    continue
                
                # Get text
                text = (item.armenian_audio if hasattr(item, 'armenian_audio') and item.armenian_audio 
                       else item.armenian_display)
                
                # Generate
                if tts.synthesize_to_file(text, output_path, voice):
                    print(f"      ‚úÖ {item.audio_key}.mp3")
                    stats["success"] += 1
                else:
                    print(f"      ‚ùå {item.audio_key}.mp3 FAILED")
                    stats["failed"] += 1
    
    return stats


def generate_verb_audio(tts: DualVoiceTTS, voices: list, output_dir: str = "audio_library"):
    """Generate audio for all verb conjugations with pronouns and pauses."""
    
    print("\n" + "="*70)
    print("üî§ GENERATING VERB CONJUGATION AUDIO")
    print("="*70)
    
    # Western Armenian pronouns
    PRONOUNS = ["‘µ’Ω", "‘¥’∏÷Ç’∂", "‘±’∂’´’Ø’°", "’Ñ’•’∂÷Ñ", "‘¥’∏÷Ç÷Ñ", "‘±’∂’∏’∂÷Ñ"]
    
    stats = {"total": 0, "success": 0, "failed": 0, "skipped": 0}
    
    for voice in voices:
        print(f"\n   Voice: {voice.capitalize()}")
        voice_dir = f"{output_dir}/verbs/{voice}"
        
        for verb_key, verb in VERBS.items():
            for tense in ["present", "past", "future"]:
                stats["total"] += 1
                
                # Filename: verb_to_{verb_key}_{tense}.mp3
                output_path = f"{voice_dir}/verb_to_{verb.verb_key}_{tense}.mp3"
                
                # Skip if exists
                if os.path.exists(output_path):
                    stats["skipped"] += 1
                    continue
                
                # Get conjugations for this tense
                conjugations = verb.conjugations[tense]
                
                # Build SSML with pronouns and pauses
                # Format: "‘µ’Ω ’•’¥ <break time="750ms"/> ‘¥’∏÷Ç’∂ ’•’Ω <break time="750ms"/> ..."
                ssml_parts = []
                for pronoun, conjugation in zip(PRONOUNS, conjugations):
                    # Apply pronunciation fixes to each conjugation
                    fixed_conjugation = apply_western_fixes(conjugation)
                    ssml_parts.append(f"{pronoun} {fixed_conjugation}")
                
                # Join with pauses (750ms between each)
                ssml_text = '<break time="750ms"/>'.join(ssml_parts)
                
                # Get voice name for SSML
                voice_name = tts.VOICES[voice]
                
                # Wrap in SSML speak tag with voice declaration
                ssml_full = f'''<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="hy-AM">
                    <voice name="{voice_name}">{ssml_text}</voice>
                </speak>'''
                
                # Generate using SSML
                if tts.synthesize_to_file_ssml(ssml_full, output_path, voice):
                    print(f"      ‚úÖ verb_to_{verb.verb_key}_{tense}.mp3")
                    stats["success"] += 1
                else:
                    print(f"      ‚ùå verb_to_{verb.verb_key}_{tense}.mp3 FAILED")
                    stats["failed"] += 1
    
    return stats


def generate_single_lesson(
    lesson_id: str, 
    tts: DualVoiceTTS, 
    voices: list, 
    output_dir: str = "audio_library"
):
    """Generate audio for a single lesson only."""
    
    if lesson_id not in LESSONS:
        print(f"‚ùå Lesson '{lesson_id}' not found!")
        print(f"Available lessons: {', '.join(LESSONS.keys())}")
        return
    
    lesson = LESSONS[lesson_id]
    print(f"\nüéØ Generating audio for: {lesson.title}")
    
    # Route to appropriate generator
    if lesson.lesson_type == "vocabulary":
        # Temporarily filter
        temp_lessons = {lesson_id: lesson}
        original = LESSONS.copy()
        LESSONS.clear()
        LESSONS.update(temp_lessons)
        
        stats = generate_vocabulary_audio(tts, voices, output_dir)
        
        LESSONS.clear()
        LESSONS.update(original)
    
    elif lesson.lesson_type == "sentences":
        temp_lessons = {lesson_id: lesson}
        original = LESSONS.copy()
        LESSONS.clear()
        LESSONS.update(temp_lessons)
        
        stats = generate_sentence_audio(tts, voices, output_dir)
        
        LESSONS.clear()
        LESSONS.update(original)
    
    print_statistics(stats)


def generate_all_audio(tts: DualVoiceTTS, voices: list, output_dir: str = "audio_library"):
    """Generate ALL audio files."""
    
    print("\n" + "="*70)
    print("üéôÔ∏è  ARMENIAN TUTOR - DUAL-VOICE AUDIO GENERATION")
    print("="*70)
    print(f"Output directory: {output_dir}/")
    print(f"Voices: {', '.join([v.capitalize() for v in voices])}")
    print("="*70)
    
    # Generate all types
    vocab_stats = generate_vocabulary_audio(tts, voices, output_dir)
    sentence_stats = generate_sentence_audio(tts, voices, output_dir)
    verb_stats = generate_verb_audio(tts, voices, output_dir)
    
    # Combine statistics
    total_stats = {
        "total": vocab_stats["total"] + sentence_stats["total"] + verb_stats["total"],
        "success": vocab_stats["success"] + sentence_stats["success"] + verb_stats["success"],
        "failed": vocab_stats["failed"] + sentence_stats["failed"] + verb_stats["failed"],
        "skipped": vocab_stats["skipped"] + sentence_stats["skipped"] + verb_stats["skipped"],
    }
    
    print_statistics(total_stats)


def print_statistics(stats: dict):
    """Print generation statistics."""
    print("\n" + "="*70)
    print("üìä GENERATION COMPLETE")
    print("="*70)
    print(f"Total files:    {stats['total']}")
    print(f"‚úÖ Generated:   {stats['success']}")
    print(f"‚è≠Ô∏è  Skipped:     {stats['skipped']} (already exist)")
    print(f"‚ùå Failed:      {stats['failed']}")
    
    if stats['success'] > 0:
        print(f"\nüí° Next steps:")
        print(f"1. Test audio files locally")
        print(f"2. Upload to GitHub: audio_library/")
        print(f"3. Commit and push to main branch")
    
    if stats['failed'] > 0:
        print(f"\n‚ö†Ô∏è  Some files failed to generate. Check errors above.")


# ============================================================================
# COMMAND LINE INTERFACE
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="Generate Armenian audio files with dual voice support"
    )
    parser.add_argument(
        "--voice",
        choices=["male", "female", "both"],
        default="both",
        help="Which voice(s) to generate (default: both)"
    )
    parser.add_argument(
        "--lesson",
        help="Generate specific lesson only (e.g., 'lesson_01')"
    )
    parser.add_argument(
        "--output",
        default="audio_library",
        help="Output directory (default: audio_library)"
    )
    parser.add_argument(
        "--skip-verbs",
        action="store_true",
        help="Skip verb conjugation generation"
    )
    
    args = parser.parse_args()
    
    # Get Azure credentials from Key Vault
    api_key = get_speech_key_from_vault()
    region = os.getenv("AZURE_SPEECH_REGION", "eastus")
    
    # Determine voices to generate
    voices = []
    if args.voice == "both":
        voices = ["male", "female"]
    else:
        voices = [args.voice]
    
    # Initialize TTS
    tts = DualVoiceTTS(api_key, region)
    
    # Generate audio
    if args.lesson:
        generate_single_lesson(args.lesson, tts, voices, args.output)
    else:
        generate_all_audio(tts, voices, args.output)


if __name__ == "__main__":
    main()
